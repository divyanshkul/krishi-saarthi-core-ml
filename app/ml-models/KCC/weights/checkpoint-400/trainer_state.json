{
  "best_global_step": 200,
  "best_metric": 1.4841324090957642,
  "best_model_checkpoint": "./tinyllama_prompt_tuned/checkpoint-200",
  "epoch": 20.0,
  "eval_steps": 50,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.2679978609085083,
      "learning_rate": 0.0018,
      "loss": 2.045,
      "step": 10
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7981447577476501,
      "learning_rate": 0.0038,
      "loss": 1.5934,
      "step": 20
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.8153302073478699,
      "learning_rate": 0.0058,
      "loss": 1.4675,
      "step": 30
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.31863608956336975,
      "learning_rate": 0.0078000000000000005,
      "loss": 1.5349,
      "step": 40
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.3256685733795166,
      "learning_rate": 0.0098,
      "loss": 1.4957,
      "step": 50
    },
    {
      "epoch": 2.5,
      "eval_loss": 1.6316173076629639,
      "eval_runtime": 1.1503,
      "eval_samples_per_second": 17.387,
      "eval_steps_per_second": 17.387,
      "step": 50
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.22416090965270996,
      "learning_rate": 0.009742857142857143,
      "loss": 1.3342,
      "step": 60
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.34169650077819824,
      "learning_rate": 0.009457142857142857,
      "loss": 1.3395,
      "step": 70
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.3943297863006592,
      "learning_rate": 0.009171428571428572,
      "loss": 1.4424,
      "step": 80
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.34006592631340027,
      "learning_rate": 0.008885714285714287,
      "loss": 1.3048,
      "step": 90
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2020917534828186,
      "learning_rate": 0.0086,
      "loss": 1.2581,
      "step": 100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.531732201576233,
      "eval_runtime": 1.1589,
      "eval_samples_per_second": 17.258,
      "eval_steps_per_second": 17.258,
      "step": 100
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.1996646523475647,
      "learning_rate": 0.008314285714285715,
      "loss": 1.1915,
      "step": 110
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.3304358720779419,
      "learning_rate": 0.008028571428571428,
      "loss": 1.2602,
      "step": 120
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.41975387930870056,
      "learning_rate": 0.0077428571428571425,
      "loss": 1.2262,
      "step": 130
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.3717080354690552,
      "learning_rate": 0.007457142857142857,
      "loss": 1.1333,
      "step": 140
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.3124062716960907,
      "learning_rate": 0.007171428571428572,
      "loss": 1.1402,
      "step": 150
    },
    {
      "epoch": 7.5,
      "eval_loss": 1.5012286901474,
      "eval_runtime": 1.1738,
      "eval_samples_per_second": 17.039,
      "eval_steps_per_second": 17.039,
      "step": 150
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.29284876585006714,
      "learning_rate": 0.006885714285714287,
      "loss": 1.1772,
      "step": 160
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.4954044818878174,
      "learning_rate": 0.006600000000000001,
      "loss": 1.1057,
      "step": 170
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.3520280718803406,
      "learning_rate": 0.006314285714285715,
      "loss": 1.1386,
      "step": 180
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.24977752566337585,
      "learning_rate": 0.006028571428571429,
      "loss": 1.1254,
      "step": 190
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.399443656206131,
      "learning_rate": 0.005742857142857143,
      "loss": 1.0805,
      "step": 200
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.4841324090957642,
      "eval_runtime": 1.1693,
      "eval_samples_per_second": 17.104,
      "eval_steps_per_second": 17.104,
      "step": 200
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.4773213267326355,
      "learning_rate": 0.0054571428571428575,
      "loss": 1.1008,
      "step": 210
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.5367088913917542,
      "learning_rate": 0.005171428571428572,
      "loss": 1.0362,
      "step": 220
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.2607485055923462,
      "learning_rate": 0.004885714285714286,
      "loss": 1.0172,
      "step": 230
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.24898409843444824,
      "learning_rate": 0.0046,
      "loss": 1.0448,
      "step": 240
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.45434603095054626,
      "learning_rate": 0.004314285714285714,
      "loss": 0.8814,
      "step": 250
    },
    {
      "epoch": 12.5,
      "eval_loss": 1.53128182888031,
      "eval_runtime": 1.1815,
      "eval_samples_per_second": 16.928,
      "eval_steps_per_second": 16.928,
      "step": 250
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.34300848841667175,
      "learning_rate": 0.004028571428571428,
      "loss": 1.0663,
      "step": 260
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.47785684466362,
      "learning_rate": 0.003742857142857143,
      "loss": 0.866,
      "step": 270
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.5090005397796631,
      "learning_rate": 0.003457142857142857,
      "loss": 1.0693,
      "step": 280
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.33424779772758484,
      "learning_rate": 0.003171428571428571,
      "loss": 0.9304,
      "step": 290
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.5778788924217224,
      "learning_rate": 0.002885714285714286,
      "loss": 0.9069,
      "step": 300
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.535983681678772,
      "eval_runtime": 1.1964,
      "eval_samples_per_second": 16.716,
      "eval_steps_per_second": 16.716,
      "step": 300
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.2602008283138275,
      "learning_rate": 0.0026000000000000003,
      "loss": 0.855,
      "step": 310
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.3373083770275116,
      "learning_rate": 0.0023142857142857145,
      "loss": 0.9083,
      "step": 320
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.48288318514823914,
      "learning_rate": 0.0020285714285714286,
      "loss": 0.8363,
      "step": 330
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.3603571951389313,
      "learning_rate": 0.001742857142857143,
      "loss": 0.8733,
      "step": 340
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.3654209077358246,
      "learning_rate": 0.0014571428571428572,
      "loss": 0.7683,
      "step": 350
    },
    {
      "epoch": 17.5,
      "eval_loss": 1.557891607284546,
      "eval_runtime": 1.2018,
      "eval_samples_per_second": 16.641,
      "eval_steps_per_second": 16.641,
      "step": 350
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.5741894841194153,
      "learning_rate": 0.0011714285714285715,
      "loss": 0.8481,
      "step": 360
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.4465128779411316,
      "learning_rate": 0.0008857142857142857,
      "loss": 0.75,
      "step": 370
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.32377344369888306,
      "learning_rate": 0.0006,
      "loss": 0.7841,
      "step": 380
    },
    {
      "epoch": 19.5,
      "grad_norm": 0.49894940853118896,
      "learning_rate": 0.0003142857142857143,
      "loss": 0.7263,
      "step": 390
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.36504971981048584,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.7697,
      "step": 400
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.5641963481903076,
      "eval_runtime": 1.1919,
      "eval_samples_per_second": 16.78,
      "eval_steps_per_second": 16.78,
      "step": 400
    }
  ],
  "logging_steps": 10,
  "max_steps": 400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5084835269836800.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
