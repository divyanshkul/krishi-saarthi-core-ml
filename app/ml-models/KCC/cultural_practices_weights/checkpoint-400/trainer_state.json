{
  "best_global_step": 250,
  "best_metric": 1.0158021450042725,
  "best_model_checkpoint": "/teamspace/studios/this_studio/KCC_cultural_practices/tinyllama_prompt_tuned/checkpoint-200",
  "epoch": 20.0,
  "eval_steps": 50,
  "global_step": 400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.5,
      "grad_norm": 1.3713452816009521,
      "learning_rate": 0.0018,
      "loss": 2.0442,
      "step": 10
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3062279224395752,
      "learning_rate": 0.0038,
      "loss": 1.5366,
      "step": 20
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.0414375066757202,
      "learning_rate": 0.0058,
      "loss": 1.3688,
      "step": 30
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6969338059425354,
      "learning_rate": 0.0078000000000000005,
      "loss": 1.2294,
      "step": 40
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.4559914171695709,
      "learning_rate": 0.0098,
      "loss": 1.1885,
      "step": 50
    },
    {
      "epoch": 2.5,
      "eval_loss": 1.194317102432251,
      "eval_runtime": 1.1709,
      "eval_samples_per_second": 17.08,
      "eval_steps_per_second": 17.08,
      "step": 50
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6309990286827087,
      "learning_rate": 0.009742857142857143,
      "loss": 1.0768,
      "step": 60
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.454565167427063,
      "learning_rate": 0.009457142857142857,
      "loss": 0.9786,
      "step": 70
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.4857950806617737,
      "learning_rate": 0.009171428571428572,
      "loss": 1.0457,
      "step": 80
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.3770223557949066,
      "learning_rate": 0.008885714285714287,
      "loss": 1.0397,
      "step": 90
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.4083718955516815,
      "learning_rate": 0.0086,
      "loss": 0.8072,
      "step": 100
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.0774534940719604,
      "eval_runtime": 1.1773,
      "eval_samples_per_second": 16.989,
      "eval_steps_per_second": 16.989,
      "step": 100
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.3639642298221588,
      "learning_rate": 0.008314285714285715,
      "loss": 0.857,
      "step": 110
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.4083084762096405,
      "learning_rate": 0.008028571428571428,
      "loss": 0.8958,
      "step": 120
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.34795233607292175,
      "learning_rate": 0.0077428571428571425,
      "loss": 0.8212,
      "step": 130
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.34416109323501587,
      "learning_rate": 0.007457142857142857,
      "loss": 0.8645,
      "step": 140
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.45583638548851013,
      "learning_rate": 0.007171428571428572,
      "loss": 0.7409,
      "step": 150
    },
    {
      "epoch": 7.5,
      "eval_loss": 1.0403430461883545,
      "eval_runtime": 1.1883,
      "eval_samples_per_second": 16.83,
      "eval_steps_per_second": 16.83,
      "step": 150
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.3942515552043915,
      "learning_rate": 0.006885714285714287,
      "loss": 0.8668,
      "step": 160
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.3917987048625946,
      "learning_rate": 0.006600000000000001,
      "loss": 0.7971,
      "step": 170
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.38544026017189026,
      "learning_rate": 0.006314285714285715,
      "loss": 0.7562,
      "step": 180
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.45398423075675964,
      "learning_rate": 0.006028571428571429,
      "loss": 0.6826,
      "step": 190
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.36629897356033325,
      "learning_rate": 0.005742857142857143,
      "loss": 0.7717,
      "step": 200
    },
    {
      "epoch": 10.0,
      "eval_loss": 1.0162878036499023,
      "eval_runtime": 1.1835,
      "eval_samples_per_second": 16.898,
      "eval_steps_per_second": 16.898,
      "step": 200
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.419467031955719,
      "learning_rate": 0.0054571428571428575,
      "loss": 0.6649,
      "step": 210
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.5324990153312683,
      "learning_rate": 0.005171428571428572,
      "loss": 0.7258,
      "step": 220
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.4487813115119934,
      "learning_rate": 0.004885714285714286,
      "loss": 0.6182,
      "step": 230
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.4127357006072998,
      "learning_rate": 0.0046,
      "loss": 0.7134,
      "step": 240
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.45517072081565857,
      "learning_rate": 0.004314285714285714,
      "loss": 0.6826,
      "step": 250
    },
    {
      "epoch": 12.5,
      "eval_loss": 1.0158021450042725,
      "eval_runtime": 1.191,
      "eval_samples_per_second": 16.793,
      "eval_steps_per_second": 16.793,
      "step": 250
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.5798095464706421,
      "learning_rate": 0.004028571428571428,
      "loss": 0.5926,
      "step": 260
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.5913967490196228,
      "learning_rate": 0.003742857142857143,
      "loss": 0.6265,
      "step": 270
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.3266330063343048,
      "learning_rate": 0.003457142857142857,
      "loss": 0.6076,
      "step": 280
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.4754783511161804,
      "learning_rate": 0.003171428571428571,
      "loss": 0.5573,
      "step": 290
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.6175996661186218,
      "learning_rate": 0.002885714285714286,
      "loss": 0.5638,
      "step": 300
    },
    {
      "epoch": 15.0,
      "eval_loss": 1.0167511701583862,
      "eval_runtime": 1.2271,
      "eval_samples_per_second": 16.298,
      "eval_steps_per_second": 16.298,
      "step": 300
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.49564358592033386,
      "learning_rate": 0.0026000000000000003,
      "loss": 0.4957,
      "step": 310
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.6467325687408447,
      "learning_rate": 0.0023142857142857145,
      "loss": 0.5496,
      "step": 320
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.5273657441139221,
      "learning_rate": 0.0020285714285714286,
      "loss": 0.5239,
      "step": 330
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.4862958490848541,
      "learning_rate": 0.001742857142857143,
      "loss": 0.4714,
      "step": 340
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.5254262685775757,
      "learning_rate": 0.0014571428571428572,
      "loss": 0.4403,
      "step": 350
    },
    {
      "epoch": 17.5,
      "eval_loss": 1.0587202310562134,
      "eval_runtime": 1.3266,
      "eval_samples_per_second": 15.076,
      "eval_steps_per_second": 15.076,
      "step": 350
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.4739876687526703,
      "learning_rate": 0.0011714285714285715,
      "loss": 0.4941,
      "step": 360
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.4553152620792389,
      "learning_rate": 0.0008857142857142857,
      "loss": 0.3808,
      "step": 370
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.5554161071777344,
      "learning_rate": 0.0006,
      "loss": 0.4807,
      "step": 380
    },
    {
      "epoch": 19.5,
      "grad_norm": 0.4977474510669708,
      "learning_rate": 0.0003142857142857143,
      "loss": 0.4538,
      "step": 390
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.502751350402832,
      "learning_rate": 2.857142857142857e-05,
      "loss": 0.3392,
      "step": 400
    },
    {
      "epoch": 20.0,
      "eval_loss": 1.0791593790054321,
      "eval_runtime": 1.578,
      "eval_samples_per_second": 12.674,
      "eval_steps_per_second": 12.674,
      "step": 400
    }
  ],
  "logging_steps": 10,
  "max_steps": 400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5084835269836800.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
